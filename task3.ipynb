{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+----------------+---------+\n",
      "|report_date|total_purchase_amt|total_redeem_amt|day_index|\n",
      "+-----------+------------------+----------------+---------+\n",
      "| 2014-08-08|         233903717|       311648757|      403|\n",
      "| 2014-08-24|         130195484|       191080151|      419|\n",
      "| 2014-07-28|         371762756|       345986909|      392|\n",
      "| 2014-07-04|         211649838|       264494550|      368|\n",
      "| 2014-03-28|         225966355|       405443946|      270|\n",
      "| 2014-08-16|         215059736|       219214339|      411|\n",
      "| 2014-07-20|         176449304|       174462836|      384|\n",
      "| 2014-04-08|         354770149|       250015131|      281|\n",
      "| 2014-05-04|         303087562|       413222034|      307|\n",
      "| 2014-05-28|         276134813|       415891684|      331|\n",
      "| 2014-06-24|         245450766|       428471509|      358|\n",
      "| 2014-03-20|         365011495|       336076380|      262|\n",
      "| 2014-04-16|         387847838|       255914640|      289|\n",
      "| 2014-05-12|         325108597|       293952908|      315|\n",
      "| 2014-06-08|         302171269|       169525332|      342|\n",
      "| 2014-04-24|         318358891|       224536754|      297|\n",
      "| 2014-05-20|         453955303|       260040720|      323|\n",
      "| 2014-06-16|         387308484|       492349489|      350|\n",
      "| 2014-07-12|         177644343|       149081488|      376|\n",
      "| 2013-11-20|         166163002|        86951218|      142|\n",
      "+-----------+------------------+----------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, datediff, lit,desc\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# 创建SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Linear Regression Forecast\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 1. 从CSV文件加载数据\n",
    "file_path = \"output/task1.in_out_daily/part-00000-f000be85-9759-4374-bdda-566c8ba19423-c000.csv\"  \n",
    "data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# 2. 提取report_date和total_purchase_amt\n",
    "# 将report_date转换为数值型，相对于基础日期2013-07-01的偏移天数\n",
    "base_date = \"2013-07-01\"\n",
    "data = data.withColumn(\"report_date\", to_date(col(\"report_date\"), 'yyyyMMdd'))\n",
    "\n",
    "data = data.withColumn(\"day_index\", datediff(col(\"report_date\"), lit(base_date)))\n",
    "data.show()\n",
    "purchase_df = data.select(\"day_index\", \"total_purchase_amt\").orderBy(\"day_index\")\n",
    "redeem_df = data.select(\"day_index\", \"total_redeem_amt\").orderBy(\"day_index\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 数据预处理\n",
    "def preprocess_data(df, index_col, value_col):\n",
    "    assembler = VectorAssembler(inputCols=index_col, outputCol=\"features\")\n",
    "    df = assembler.transform(df).select(\"features\", col(value_col).alias(\"label\"))\n",
    "    return df\n",
    "processed_purchase_df = preprocess_data(purchase_df, [\"day_index\"], \"total_purchase_amt\")\n",
    "processed_redeem_df = preprocess_data(redeem_df, [\"day_index\"], \"total_redeem_amt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/13 16:06:44 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+\n",
      "|day_index|features|          prediction|\n",
      "+---------+--------+--------------------+\n",
      "|      427| [427.0]| 3.617769699730947E8|\n",
      "|      428| [428.0]| 3.624542411184964E8|\n",
      "|      429| [429.0]|  3.63131512263898E8|\n",
      "|      430| [430.0]|3.6380878340929973E8|\n",
      "|      431| [431.0]| 3.644860545547013E8|\n",
      "|      432| [432.0]| 3.651633257001029E8|\n",
      "|      433| [433.0]|3.6584059684550464E8|\n",
      "|      434| [434.0]|3.6651786799090624E8|\n",
      "|      435| [435.0]|3.6719513913630795E8|\n",
      "|      436| [436.0]|3.6787241028170955E8|\n",
      "|      437| [437.0]|3.6854968142711115E8|\n",
      "|      438| [438.0]|3.6922695257251287E8|\n",
      "|      439| [439.0]|3.6990422371791446E8|\n",
      "|      440| [440.0]| 3.705814948633162E8|\n",
      "|      441| [441.0]| 3.712587660087178E8|\n",
      "|      442| [442.0]| 3.719360371541194E8|\n",
      "|      443| [443.0]| 3.726133082995211E8|\n",
      "|      444| [444.0]| 3.732905794449227E8|\n",
      "|      445| [445.0]| 3.739678505903244E8|\n",
      "|      446| [446.0]|  3.74645121735726E8|\n",
      "+---------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. 训练线性回归模型\n",
    "\n",
    "\n",
    "# lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "model1 = lr.fit(processed_purchase_df)\n",
    "\n",
    "# 5. 预测未来30天\n",
    "def predict_future(model, start_index, num_days):\n",
    "    future_data = [(start_index + i,) for i in range(1, num_days + 1)]\n",
    "    future_df = spark.createDataFrame(future_data, [\"day_index\"])\n",
    "    assembler = VectorAssembler(inputCols=[\"day_index\"], outputCol=\"features\")\n",
    "    future_df = assembler.transform(future_df)\n",
    "    predictions = model.transform(future_df)\n",
    "    return predictions\n",
    "\n",
    "last_day_index = purchase_df.selectExpr(\"max(day_index) as day_index\").collect()[0][\"day_index\"]\n",
    "purchase_predictions = predict_future(model1, last_day_index, 30)\n",
    "# 显示预测结果\n",
    "purchase_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/13 16:07:05 WARN Instrumentation: [7e078376] regParam is zero, which might cause numerical instability and overfitting.\n",
      "24/12/13 16:07:06 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+\n",
      "|day_index|features|          prediction|\n",
      "+---------+--------+--------------------+\n",
      "|      427| [427.0]| 3.452366435413134E8|\n",
      "|      428| [428.0]| 3.460541023303232E8|\n",
      "|      429| [429.0]| 3.468715611193331E8|\n",
      "|      430| [430.0]| 3.476890199083429E8|\n",
      "|      431| [431.0]|3.4850647869735277E8|\n",
      "|      432| [432.0]| 3.493239374863626E8|\n",
      "|      433| [433.0]|3.5014139627537245E8|\n",
      "|      434| [434.0]|3.5095885506438226E8|\n",
      "|      435| [435.0]|3.5177631385339206E8|\n",
      "|      436| [436.0]|3.5259377264240193E8|\n",
      "|      437| [437.0]|3.5341123143141174E8|\n",
      "|      438| [438.0]| 3.542286902204216E8|\n",
      "|      439| [439.0]| 3.550461490094314E8|\n",
      "|      440| [440.0]| 3.558636077984413E8|\n",
      "|      441| [441.0]| 3.566810665874511E8|\n",
      "|      442| [442.0]|3.5749852537646097E8|\n",
      "|      443| [443.0]| 3.583159841654708E8|\n",
      "|      444| [444.0]| 3.591334429544806E8|\n",
      "|      445| [445.0]|3.5995090174349046E8|\n",
      "|      446| [446.0]|3.6076836053250027E8|\n",
      "+---------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LinearRegression(featuresCol=\"features\",labelCol=\"label\")\n",
    "model2=lr.fit(processed_redeem_df)\n",
    "redeem_predictions=predict_future(model2,last_day_index,30)\n",
    "redeem_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr, date_format\n",
    "result1=purchase_predictions.select(\n",
    "    col(\"day_index\"),\n",
    "    col(\"prediction\")\n",
    ")\n",
    "result2=redeem_predictions.select(\n",
    "    col(\"day_index\"),\n",
    "    col(\"prediction\").alias(\"prediction2\")\n",
    ")\n",
    "df=result1.join(result2,on=[\"day_index\"],how=\"inner\")\n",
    "# 将base_date转换为日期类型\n",
    "\n",
    "# 计算新的日期列\n",
    "df_with_date = df.withColumn(\n",
    "    \"date\",\n",
    "    date_format(\n",
    "        expr(f\"date_add(to_date('{base_date}'), cast(day_index as INT))\"),\n",
    "        \"yyyyMMdd\"\n",
    "    )\n",
    ")\n",
    "result=df_with_date.select(\n",
    "    col(\"date\").alias('report_date'), \n",
    "    col(\"prediction\").alias('total_purchase_amt'),\n",
    "    col(\"prediction2\").alias('total_redeem_amt')\n",
    "    )\n",
    "#转换成整数\n",
    "result=result.withColumn(\"total_purchase_amt\",result[\"total_purchase_amt\"].cast(\"int\"))\n",
    "result=result.withColumn(\"total_redeem_amt\",result[\"total_redeem_amt\"].cast(\"int\"))\n",
    "\n",
    "result.coalesce(1).write.csv(\"output/task3.result\", header=False, mode=\"overwrite\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
